{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3bb03e-d16e-490a-8ef5-45c508ed85c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc568821-6767-410f-9976-1437b28a60a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/02 13:36:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/02 13:36:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "\t\t.master(\"local[*]\") \\\n",
    "\t\t.config(\"spark.executor.memory\", \"2gb\") \\\n",
    "\t\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa2b24-2afb-471e-8a39-24c0ab5f0658",
   "metadata": {},
   "source": [
    "# 1. Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9918df1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|word count from W...|\n",
      "|the word count is...|\n",
      "|is required to st...|\n",
      "|proceedings journ...|\n",
      "|the translation j...|\n",
      "|and reading speed...|\n",
      "|six characters to...|\n",
      "|In non fiction Se...|\n",
      "|This section does...|\n",
      "|reliable sources ...|\n",
      "|Variations in the...|\n",
      "|which words don't...|\n",
      "|is a broad consen...|\n",
      "|The consensus is ...|\n",
      "|word boundaries a...|\n",
      "|characters such a...|\n",
      "|Different word co...|\n",
      "|details and on wh...|\n",
      "|of most major wor...|\n",
      "|handwriting or wi...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lines_df = spark.read.text('data/wordcount.txt')\n",
    "lines_df.printSchema()\n",
    "lines_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c3c397",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|     the|   38|\n",
      "|       a|   28|\n",
      "|      of|   25|\n",
      "|    word|   24|\n",
      "|     and|   23|\n",
      "|   words|   21|\n",
      "|      is|   19|\n",
      "|      to|   18|\n",
      "|      in|   11|\n",
      "|   count|   11|\n",
      "|      or|   11|\n",
      "|     for|   10|\n",
      "|      as|    9|\n",
      "|     may|    8|\n",
      "|      be|    8|\n",
      "|    text|    8|\n",
      "|      on|    7|\n",
      "|    such|    7|\n",
      "|counting|    6|\n",
      "|     can|    5|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = lines_df.withColumn('word', F.explode(F.split(F.col('value'), ' '))) \\\n",
    "\t\t.groupBy('word').count().sort('count', ascending=False)\n",
    "words_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75b7f97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "words_df.cache() # saves it to MEMORY_AND_DISK\n",
    "assert 381 == words_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17fe0ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# How many words have more than 4 occurrences\n",
    "filtered_words_df = words_df.filter(F.col('count') > 4)\n",
    "assert 26 == filtered_words_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d60358",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Tweet Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee278ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_df = spark.read.json('data/reduced-tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec964a7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      "\n",
      "+--------------------+------------------+-----------------+--------------------+-------------------+\n",
      "|             country|                id|            place|                text|               user|\n",
      "+--------------------+------------------+-----------------+--------------------+-------------------+\n",
      "|               India|572692378957430785|           Orissa|@always_nidhi @Yo...|    Srkian_nishu :)|\n",
      "|       United States|572575240615796737|        Manhattan|@OnlyDancers Bell...| TagineDiningGlobal|\n",
      "|       United States|572575243883036672|        Claremont|1/ \"Without the a...|        Daniel Beer|\n",
      "|       United States|572575252020109313|           Vienna|idk why people ha...|   someone actually|\n",
      "|       United States|572575274539356160|           Boston|Taste of Iceland!...|     BostonAttitude|\n",
      "|       United States|572647819401670656|          Suwanee|Know what you don...|Collin A. Zimmerman|\n",
      "|           Indonesia|572647831053312000|      Mario Riawa|Serasi ade haha @...|   Rinie Syamsuddin|\n",
      "|           Indonesia|572647839521767425|    Bogor Selatan|Akhirnya bisa jug...|       Vinny Sylvia|\n",
      "|       United States|572647841220337664|          Norwalk|@BeezyDH_ it's li...|                Cas|\n",
      "|       United States|572647842277396480|           Santee| obsessed with music|               kimo|\n",
      "|       United States|572631750163234816|        Tennessee|@blakeshelton You...|        Jeff Morton|\n",
      "|           Indonesia|572631763115249664|           Gambir|Happy Birhday Ps....|        Rensus Paul|\n",
      "|       United States|572606799712428033|   North Carolina|One night I'm ext...|                 KC|\n",
      "|       United States|572606799649640449|        Baltimore|@DjGregStreet STO...|      #QuissyUpSoon|\n",
      "|       United States|572606809216663552|          Cypress|always getting in...|                 lo|\n",
      "|Negara Brunei Dar...|572606812081410048|           Brunei|nigga in paris ht...|           hafizzul|\n",
      "|       United States|572616136963055616|         Portland|Boutta fall aslee...|          Princessâœ¨|\n",
      "|       United States|572616139987144704|         Kentucky|Canadians are tak...|       Nene Kiameso|\n",
      "|       United States|572616165786185728|         Wahpeton|Chicago takin ove...|              Chase|\n",
      "|      United Kingdom|572667477949353984|Ashton-under-Lyne|@traceyb65 I'm up...|             stefan|\n",
      "+--------------------+------------------+-----------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.printSchema()\n",
    "tweets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd857ebb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find all the persons mentioned on tweets\n",
    "def extract_mentions(words: List[str]) -> List[str]:\n",
    "\tmentions = []\n",
    "\tfor word in words:\n",
    "\t\tif len(word) > 1 and word[0] == '@':\n",
    "\t\t\tmentions.append(word.lower())\n",
    "\n",
    "\treturn mentions\n",
    "\n",
    "filtered_mentions_df = F.udf(lambda z: extract_mentions(z), types.ArrayType(types.StringType()))\n",
    "spark.udf.register(\"filter_mentions\", filtered_mentions_df)\n",
    "mentions_df = tweets_df.withColumn('mention', F.explode(filtered_mentions_df(F.split(F.col('text'), ' ')))).select('mention')\n",
    "mentions_df.cache()\n",
    "assert mentions_df.count() == 4462\n",
    "assert mentions_df.filter(F.col('mention') == \"@jordinsparks\").count() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f7006a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find all the hashtags mentioned on tweets\n",
    "@F.udf(returnType=types.ArrayType(types.StringType()))\n",
    "def extract_hashtags(words: List[str]) -> List[str]:\n",
    "\tmentions = []\n",
    "\tfor word in words:\n",
    "\t\tif len(word) > 1 and word[0] == '#':\n",
    "\t\t\tmentions.append(word.lower())\n",
    "\n",
    "\treturn mentions\n",
    "\n",
    "hashtags_df = tweets_df.select('text').select(F.explode(extract_hashtags(F.split(F.col('text'), ' '))))\n",
    "\n",
    "hashtags_df.cache()\n",
    "assert hashtags_df.count() == 5262\n",
    "assert hashtags_df.where(F.col('col') == '#youtube').count() == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa42d7cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find same hashtags and mentions\n",
    "hashtags_stripped_df = hashtags_df.drop_duplicates().select(F.substring('col', pos=2, len=1000).alias(\"text\"))\n",
    "mentions_stripped_df = mentions_df.drop_duplicates().select(F.substring('mention', pos=2, len=1000).alias(\"text\"))\n",
    "\n",
    "same_hashtags_mentions_df = hashtags_stripped_df.join(other=mentions_stripped_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  on=hashtags_stripped_df.text == mentions_stripped_df.text,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  how=\"inner\").drop(mentions_stripped_df.text)\n",
    "\n",
    "assert same_hashtags_mentions_df.count() == 39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Useful Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://sparkbyexamples.com/\n",
    "https://spark.apache.org/examples.html\n",
    "https://databricks.com/spark/getting-started-with-apache-spark\n",
    "https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cead97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
